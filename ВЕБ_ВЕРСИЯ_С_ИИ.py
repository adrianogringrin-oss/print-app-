#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–í–ï–ë-–í–ï–†–°–ò–Ø –° –ò–ò –ü–û–î–î–ï–†–ñ–ö–û–ô
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI Vision API –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é
"""

import sys
import os

# –î–û–ë–ê–í–õ–Ø–ï–ú –ü–£–¢–ò –ö –ë–ò–ë–õ–ò–û–¢–ï–ö–ê–ú –ü–ï–†–ï–î –ò–ú–ü–û–†–¢–û–ú
# –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—É—Ç—å –∫ Homebrew Python 3.14 (–≥–¥–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏)
user_site_314 = os.path.expanduser('~/Library/Python/3.14/lib/python/site-packages')

if os.path.exists(user_site_314) and user_site_314 not in sys.path:
    sys.path.insert(0, user_site_314)

import json
import base64
import io
from http.server import HTTPServer, BaseHTTPRequestHandler
import webbrowser
import threading
import urllib.parse
from collections import Counter

try:
    from PIL import Image, ImageFilter, ImageChops
except ImportError as e:
    # –ü—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å –ø—É—Ç—å –∫ Homebrew Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º
    try:
        user_site_314 = os.path.expanduser('~/Library/Python/3.14/lib/python/site-packages')
        if os.path.exists(user_site_314):
            sys.path.insert(0, user_site_314)
        from PIL import Image, ImageFilter, ImageChops
    except ImportError:
        print("‚ùå Pillow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip3 install Pillow")
        print(f"   –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ OpenAI
HAS_OPENAI = False
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    # –ü—É—Ç–∏ —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤—ã—à–µ, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞
    try:
        import openai
        HAS_OPENAI = True
    except ImportError:
        HAS_OPENAI = False
        # –ù–µ –≤—ã–≤–æ–¥–∏–º –æ—à–∏–±–∫—É - –ò–ò —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –Ω–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
global_image = None
global_result = None
global_prompt = ""  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞
OPENAI_API_KEY = None

def load_openai_key():
    """–ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–∞ OpenAI"""
    global OPENAI_API_KEY
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª —Å –∫–ª—é—á–æ–º
    key_file = os.path.expanduser('~/.openai_api_key')
    if not OPENAI_API_KEY and os.path.exists(key_file):
        try:
            with open(key_file, 'r') as f:
                OPENAI_API_KEY = f.read().strip()
        except:
            pass
    
    return OPENAI_API_KEY is not None

def extract_with_ai(image_path, user_prompt):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI Vision API"""
    if not HAS_OPENAI:
        return None, "OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    
    if not load_openai_key():
        return None, "OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª ~/.openai_api_key –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é OPENAI_API_KEY"
    
    try:
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(image_path)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        buffer = io.BytesIO()
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if image.mode == 'RGBA':
            rgb_image = Image.new('RGB', image.size, (255, 255, 255))
            rgb_image.paste(image, mask=image.split()[3])
            rgb_image.save(buffer, format='PNG')
        else:
            image.save(buffer, format='PNG')
        
        image_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        img_width, img_height = image.size
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        prompt_lower = user_prompt.lower()
        is_entire_image = any(word in prompt_lower for word in ['–≤–µ—Å—å', '—Ü–µ–ª–∏–∫–æ–º', 'entire', 'whole', '–≤—Å–µ', 
                                                                '–≤–µ—Å—å —Ç–µ–∫—Å—Ç', '–≤–µ—Å—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', '—Ü–µ–ª–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
                                                                '—Å–æ –≤—Å–µ–≥–æ', 'from entire', 'from whole'])
        is_text_extraction = any(word in prompt_lower for word in ['—Ç–µ–∫—Å—Ç', '–Ω–∞–¥–ø–∏—Å—å', 'text', 'inscription', 
                                                                    '—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç', 'only text', '–∏–∑–≤–ª–µ–∫–∏ —Ç–µ–∫—Å—Ç'])
        
        if is_entire_image:
            # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∏–∑–≤–ª–µ—á—å –í–°–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å—é –æ–±–ª–∞—Å—Ç—å
            return {
                'x1': 0,
                'y1': 0,
                'x2': img_width,
                'y2': img_height
            }, None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ò–ò —Å —É—á–µ—Ç–æ–º –¥–µ—Ç–∞–ª–µ–π
        system_prompt = """You are an expert image segmentation assistant. Your task is to identify the COMPLETE bounding box of the content described by the user.

CRITICAL INSTRUCTIONS:
1. You MUST include the ENTIRE content - from edge to edge, top to bottom, left to right
2. DO NOT crop or cut off any part - include EVERYTHING visible
3. The bounding box should include ALL text, ALL images, ALL decorations, ALL details
4. Add a GENEROUS margin (10-20 pixels) around the content to ensure nothing is cut off
5. The bounding box should be SIGNIFICANTLY LARGER than the content itself
6. If the user mentions "–≤–µ—Å—å" (all), "—Ü–µ–ª–∏–∫–æ–º" (entire), "—Å–æ –≤—Å–µ–≥–æ" (from entire) - include the ENTIRE image
7. If extracting text - include ALL text from top to bottom, left to right
8. If extracting a design - include the COMPLETE design with all its parts

The image size is {}x{} pixels.
Return ONLY a valid JSON object with pixel coordinates in this exact format: {{"x1": number, "y1": number, "x2": number, "y2": number}}
Where:
- (x1, y1) is the top-left corner - make it WELL ABOVE and WELL LEFT of the content
- (x2, y2) is the bottom-right corner - make it WELL BELOW and WELL RIGHT of the content
- All coordinates are in pixels
- x1 < x2 and y1 < y2
- Coordinates must be within image bounds (0 to width/height)
- IMPORTANT: Make the box MUCH LARGER than the content - add 15-20 pixel margin on ALL sides

Remember: BETTER TO INCLUDE TOO MUCH than to crop anything! If unsure, make the box larger!""".format(img_width, img_height)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
        prompt_lower = user_prompt.lower()
        is_text_extraction = any(word in prompt_lower for word in ['—Ç–µ–∫—Å—Ç', '–Ω–∞–¥–ø–∏—Å—å', 'text', 'inscription', 
                                                                    '—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç', 'only text', '–∏–∑–≤–ª–µ–∫–∏ —Ç–µ–∫—Å—Ç'])
        
        if is_text_extraction:
            user_message = f"""Find the COMPLETE bounding box for: {user_prompt}

Image dimensions: {img_width} x {img_height} pixels.

SPECIAL INSTRUCTIONS FOR TEXT EXTRACTION:
- Include ALL text/inscriptions - every word, every letter, from top to bottom, left to right
- Add GENEROUS margin (15-20 pixels) around the text area
- The box should contain ALL visible text on the ENTIRE page
- Include the entire text area, not just individual words
- If user says "–≤–µ—Å—å" (all), "—Ü–µ–ª–∏–∫–æ–º" (entire), "—Å–æ –≤—Å–µ–≥–æ" (from entire) - include the ENTIRE image
- Better to include too much than to miss any text
- Make the box MUCH LARGER than the text to ensure nothing is cut off

Return ONLY the JSON object with coordinates, for example:
{{"x1": 100, "y1": 50, "x2": 400, "y2": 300}}

Do not include any other text, explanations, or formatting."""
        else:
            user_message = f"""Find the COMPLETE bounding box for: {user_prompt}

Image dimensions: {img_width} x {img_height} pixels.

CRITICAL REQUIREMENTS:
- Include the ENTIRE print/design - do NOT crop any edges
- Add 5-10 pixel margin around the print to ensure nothing is cut off
- Include ALL text, ALL images, ALL parts of the design
- The box should be LARGER than the print itself
- Better to include too much than to crop the print

Return ONLY the JSON object with coordinates, for example:
{{"x1": 100, "y1": 50, "x2": 400, "y2": 300}}

Do not include any other text, explanations, or formatting."""
        
        # –í—ã–∑—ã–≤–∞–µ–º OpenAI Vision API
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –¥–µ—à–µ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –Ω–∞—á–∞–ª–∞
            messages=[
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_message},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=100
        )
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        result_text = response.choices[0].message.content.strip()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–º)
        import re
        # –ò—â–µ–º JSON –æ–±—ä–µ–∫—Ç (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö)
        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', result_text, re.DOTALL)
        if json_match:
            try:
                coords = json.loads(json_match.group())
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –ø–æ–ª–µ–π
                if all(k in coords for k in ['x1', 'y1', 'x2', 'y2']):
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    img_width, img_height = image.size
                    
                    # –†–∞—Å—à–∏—Ä—è–µ–º –æ–±–ª–∞—Å—Ç—å –Ω–∞ 10-15% —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–µ–∑–∞—Ç—å –∫—Ä–∞—è
                    # –î–ª—è —Ç–µ–∫—Å—Ç–∞ —Ä–∞—Å—à–∏—Ä—è–µ–º –µ—â–µ –±–æ–ª—å—à–µ
                    prompt_lower = user_prompt.lower() if user_prompt else ""
                    is_text = any(word in prompt_lower for word in ['—Ç–µ–∫—Å—Ç', '–Ω–∞–¥–ø–∏—Å—å', 'text'])
                    
                    if is_text:
                        # –î–ª—è —Ç–µ–∫—Å—Ç–∞ —Ä–∞—Å—à–∏—Ä—è–µ–º –Ω–∞ 15% - –≤–∞–∂–Ω–æ –Ω–µ –æ–±—Ä–µ–∑–∞—Ç—å –±—É–∫–≤—ã
                        margin_x = int((coords['x2'] - coords['x1']) * 0.15)
                        margin_y = int((coords['y2'] - coords['y1']) * 0.15)
                    else:
                        # –î–ª—è –¥—Ä—É–≥–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - 10%
                        margin_x = int((coords['x2'] - coords['x1']) * 0.10)
                        margin_y = int((coords['y2'] - coords['y1']) * 0.10)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –æ–±–ª–∞—Å—Ç–∏ - –µ—Å–ª–∏ –æ–Ω–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ä–∞—Å—à–∏—Ä—è–µ–º
                    area_width = coords['x2'] - coords['x1']
                    area_height = coords['y2'] - coords['y1']
                    area_ratio = (area_width * area_height) / (img_width * img_height)
                    
                    # –ï—Å–ª–∏ –æ–±–ª–∞—Å—Ç—å –º–µ–Ω—å—à–µ 30% –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏–ª "–≤–µ—Å—å" –∏–ª–∏ "—Ü–µ–ª–∏–∫–æ–º" - —Ä–∞—Å—à–∏—Ä—è–µ–º –¥–æ –≤—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    if area_ratio < 0.3 and any(word in prompt_lower for word in ['–≤–µ—Å—å', '—Ü–µ–ª–∏–∫–æ–º', 'entire', 'whole', '–≤—Å–µ', '—Å–æ –≤—Å–µ–≥–æ']):
                        coords['x1'] = 0
                        coords['y1'] = 0
                        coords['x2'] = img_width
                        coords['y2'] = img_height
                    else:
                        coords['x1'] = max(0, min(int(coords['x1']) - margin_x, img_width))
                        coords['y1'] = max(0, min(int(coords['y1']) - margin_y, img_height))
                        coords['x2'] = max(coords['x1'] + 1, min(int(coords['x2']) + margin_x, img_width))
                        coords['y2'] = max(coords['y1'] + 1, min(int(coords['y2']) + margin_y, img_height))
                    return coords, None
                else:
                    return None, f"–ù–µ–ø–æ–ª–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –æ—Ç–≤–µ—Ç–µ –ò–ò: {coords}"
            except json.JSONDecodeError as e:
                return None, f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç –ò–ò: {e}\n–û—Ç–≤–µ—Ç: {result_text}"
        else:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º
            # –ò–Ω–æ–≥–¥–∞ –ò–ò –ø–∏—à–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –≤–∏–¥–µ —Ç–µ–∫—Å—Ç–∞
            nums = re.findall(r'\d+', result_text)
            if len(nums) >= 4:
                try:
                    coords = {
                        'x1': int(nums[0]),
                        'y1': int(nums[1]),
                        'x2': int(nums[2]),
                        'y2': int(nums[3])
                    }
                    img_width, img_height = image.size
                    coords['x1'] = max(0, min(coords['x1'], img_width))
                    coords['y1'] = max(0, min(coords['y1'], img_height))
                    coords['x2'] = max(coords['x1'] + 1, min(coords['x2'], img_width))
                    coords['y2'] = max(coords['y1'] + 1, min(coords['y2'], img_height))
                    return coords, None
                except:
                    pass
            
            return None, f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞ –ò–ò: {result_text}"
            
    except Exception as e:
        return None, f"–û—à–∏–±–∫–∞ –ò–ò: {str(e)}"

def remove_background_for_text(image):
    """
    –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ - —É–¥–∞–ª—è–µ—Ç —Ñ–æ–Ω –ª–∏—Å—Ç–∞, –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
    """
    width, height = image.size
    pixels = list(image.getdata())
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —è—Ä–∫–æ—Å—Ç–∏
    gray = image.convert('L')
    gray_pixels = list(gray.getdata())
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ —Ñ–æ–Ω–∞
    # –¢–µ–∫—Å—Ç –æ–±—ã—á–Ω–æ —Ç–µ–º–Ω—ã–π (–Ω–∏–∑–∫–∞—è —è—Ä–∫–æ—Å—Ç—å), —Ñ–æ–Ω —Å–≤–µ—Ç–ª—ã–π (–≤—ã—Å–æ–∫–∞—è —è—Ä–∫–æ—Å—Ç—å)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ —Ñ–æ–Ω–∞
    brightness_values = [p for p in gray_pixels]
    
    # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —è—Ä–∫–æ—Å—Ç—å
    min_brightness = min(brightness_values) if brightness_values else 0
    max_brightness = max(brightness_values) if brightness_values else 255
    avg_brightness = sum(brightness_values) / len(brightness_values) if brightness_values else 128
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —è—Ä–∫–æ—Å—Ç–∏ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω—ã
    sorted_brightness = sorted(brightness_values)
    median_brightness = sorted_brightness[len(sorted_brightness) // 2] if sorted_brightness else 128
    
    # –ê–ì–†–ï–°–°–ò–í–ù–´–ô –ü–û–†–û–ì –¥–ª—è —Ç–µ–∫—Å—Ç–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –∫—Ä–∏—Ç–µ—Ä–∏–π
    # –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–û —Ç–µ–º–Ω–µ–µ —Ñ–æ–Ω–∞
    text_threshold = median_brightness * 0.5
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –µ—Å–ª–∏ —Å—Ä–µ–¥–Ω—è—è —è—Ä–∫–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è (—Å–≤–µ—Ç–ª—ã–π —Ñ–æ–Ω), –¥–µ–ª–∞–µ–º –ø–æ—Ä–æ–≥ –µ—â–µ —Å—Ç—Ä–æ–∂–µ
    if avg_brightness > 180:  # –û—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã–π —Ñ–æ–Ω (–±–µ–ª–∞—è –±—É–º–∞–≥–∞)
        text_threshold = min(text_threshold, 90)  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
    elif avg_brightness > 150:  # –°–≤–µ—Ç–ª—ã–π —Ñ–æ–Ω
        text_threshold = min(text_threshold, 110)
    
    new_pixels = []
    
    for i, pixel in enumerate(pixels):
        r, g, b, a = pixel
        brightness = gray_pixels[i]
        
        # –ê–ì–†–ï–°–°–ò–í–ù–û–ï –£–î–ê–õ–ï–ù–ò–ï –§–û–ù–ê:
        # 1. –ï—Å–ª–∏ –ø–∏–∫—Å–µ–ª—å –æ—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã–π (> 180) - —Ç–æ—á–Ω–æ —Ñ–æ–Ω, —É–¥–∞–ª—è–µ–º
        # 2. –ï—Å–ª–∏ –ø–∏–∫—Å–µ–ª—å —Å–≤–µ—Ç–ª–µ–µ –ø–æ—Ä–æ–≥–∞ - —Ñ–æ–Ω, —É–¥–∞–ª—è–µ–º
        # 3. –ï—Å–ª–∏ –ø–∏–∫—Å–µ–ª—å —Å—Ä–µ–¥–Ω–∏–π (–º–µ–∂–¥—É –ø–æ—Ä–æ–≥–æ–º –∏ 150) - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å–µ–¥–µ–π
        
        if brightness > 180:  # –û—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã–π - —Ç–æ—á–Ω–æ —Ñ–æ–Ω (–±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)
            new_pixels.append((255, 255, 255, 0))
        elif brightness > text_threshold:
            # –°–≤–µ—Ç–ª–µ–µ –ø–æ—Ä–æ–≥–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —á–∞—Å—Ç—å—é —Ç–µ–∫—Å—Ç–∞
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ –ø–∏–∫—Å–µ–ª–∏
            y_pos = i // width
            x_pos = i % width
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ä—è–¥–æ–º —Ç–µ–º–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ (—Ç–µ–∫—Å—Ç)
            has_dark_neighbor = False
            
            for dy in [-2, -1, 0, 1, 2]:
                for dx in [-2, -1, 0, 1, 2]:
                    if dx == 0 and dy == 0:
                        continue
                    nx, ny = x_pos + dx, y_pos + dy
                    if 0 <= nx < width and 0 <= ny < height:
                        n_idx = ny * width + nx
                        n_brightness = gray_pixels[n_idx]
                        # –ï—Å–ª–∏ —Å–æ—Å–µ–¥ —Ç–µ–º–Ω—ã–π (—Ç–µ–∫—Å—Ç) - —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫—Ä–∞–π —Ç–µ–∫—Å—Ç–∞
                        if n_brightness < text_threshold:
                            has_dark_neighbor = True
                            break
                if has_dark_neighbor:
                    break
            
            # –ï—Å–ª–∏ —Ä—è–¥–æ–º –µ—Å—Ç—å —Ç–µ–º–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ –ò —Å–∞–º –ø–∏–∫—Å–µ–ª—å –Ω–µ –æ—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã–π - —Å–æ—Ö—Ä–∞–Ω—è–µ–º (–∫—Ä–∞–π —Ç–µ–∫—Å—Ç–∞)
            if has_dark_neighbor and brightness < 130:  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –∫—Ä–∞–µ–≤
                new_pixels.append((r, g, b, 255))
            else:
                # –≠—Ç–æ —Ñ–æ–Ω (–∫–ª–µ—Ç—á–∞—Ç–∞—è –±—É–º–∞–≥–∞, –ª–∏–Ω–∏–∏) - —É–¥–∞–ª—è–µ–º
                new_pixels.append((255, 255, 255, 0))
        else:
            # –¢–µ–º–Ω—ã–π –ø–∏–∫—Å–µ–ª—å - —ç—Ç–æ —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            new_pixels.append((r, g, b, 255))
    
    result = Image.new('RGBA', (width, height))
    result.putdata(new_pixels)
    
    # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –û–ß–ò–°–¢–ö–ê:
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—Ä–µ–¥–Ω–∏–µ –∏ —Å–≤–µ—Ç–ª—ã–µ –ø–∏–∫—Å–µ–ª–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é —Ç–µ–∫—Å—Ç–∞
    result_pixels = list(result.getdata())
    cleaned_pixels = []
    
    for i, pixel in enumerate(result_pixels):
        r, g, b, a = pixel
        brightness = gray_pixels[i]
        
        if a > 0:  # –ï—Å–ª–∏ –ø–∏–∫—Å–µ–ª—å –Ω–µ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π
            # –ê–ì–†–ï–°–°–ò–í–ù–û: —É–¥–∞–ª—è–µ–º –≤—Å–µ —á—Ç–æ —Å–≤–µ—Ç–ª–µ–µ 130 (–∫–ª–µ—Ç—á–∞—Ç–∞—è –±—É–º–∞–≥–∞, –ª–∏–Ω–∏–∏)
            # –¢–æ–ª—å–∫–æ –æ—á–µ–Ω—å —Ç–µ–º–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ (< 90) –∏–ª–∏ –ø–∏–∫—Å–µ–ª–∏ —Ä—è–¥–æ–º —Å —Ç–µ–º–Ω—ã–º–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            if brightness > 130:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ä—è–¥–æ–º —Ç–µ–º–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏
                y_pos = i // width
                x_pos = i % width
                has_dark_nearby = False
                
                for dy in [-1, 0, 1]:
                    for dx in [-1, 0, 1]:
                        if dx == 0 and dy == 0:
                            continue
                        nx, ny = x_pos + dx, y_pos + dy
                        if 0 <= nx < width and 0 <= ny < height:
                            n_idx = ny * width + nx
                            n_brightness = gray_pixels[n_idx]
                            if n_brightness < 90:  # –û—á–µ–Ω—å —Ç–µ–º–Ω—ã–π —Å–æ—Å–µ–¥ (—Ç–µ–∫—Å—Ç) - –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥
                                has_dark_nearby = True
                                break
                    if has_dark_nearby:
                        break
                
                if not has_dark_nearby:
                    # –ù–µ—Ç —Ç–µ–º–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π - —ç—Ç–æ —Ñ–æ–Ω, —É–¥–∞–ª—è–µ–º
                    cleaned_pixels.append((255, 255, 255, 0))
                else:
                    # –ï—Å—Ç—å —Ç–µ–º–Ω—ã–µ —Å–æ—Å–µ–¥–∏ - —ç—Ç–æ –∫—Ä–∞–π —Ç–µ–∫—Å—Ç–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                    cleaned_pixels.append(pixel)
            else:
                # –¢–µ–º–Ω—ã–π –ø–∏–∫—Å–µ–ª—å - —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                cleaned_pixels.append(pixel)
        else:
            cleaned_pixels.append(pixel)
    
    result.putdata(cleaned_pixels)
    
    # –§–ò–ù–ê–õ–¨–ù–ê–Ø –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –û–ß–ò–°–¢–ö–ê:
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á—Ç–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —è–≤–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
    final_pixels = []
    for i, pixel in enumerate(cleaned_pixels):
        r, g, b, a = pixel
        brightness = gray_pixels[i]
        
        if a > 0:  # –ï—Å–ª–∏ –ø–∏–∫—Å–µ–ª—å –Ω–µ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π
            # –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: —É–¥–∞–ª—è–µ–º –≤—Å–µ —á—Ç–æ —Å–≤–µ—Ç–ª–µ–µ 120
            # –¢–æ–ª—å–∫–æ –æ—á–µ–Ω—å —Ç–µ–º–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ (< 80) –∏–ª–∏ –ø–∏–∫—Å–µ–ª–∏ —Ä—è–¥–æ–º —Å –æ—á–µ–Ω—å —Ç–µ–º–Ω—ã–º–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            if brightness > 120:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ä—è–¥–æ–º –û–ß–ï–ù–¨ —Ç–µ–º–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ (—è–≤–Ω—ã–π —Ç–µ–∫—Å—Ç)
                y_pos = i // width
                x_pos = i % width
                has_very_dark_nearby = False
                
                for dy in [-1, 0, 1]:
                    for dx in [-1, 0, 1]:
                        if dx == 0 and dy == 0:
                            continue
                        nx, ny = x_pos + dx, y_pos + dy
                        if 0 <= nx < width and 0 <= ny < height:
                            n_idx = ny * width + nx
                            n_brightness = gray_pixels[n_idx]
                            if n_brightness < 80:  # –û—á–µ–Ω—å —Ç–µ–º–Ω—ã–π —Å–æ—Å–µ–¥ (—è–≤–Ω—ã–π —Ç–µ–∫—Å—Ç)
                                has_very_dark_nearby = True
                                break
                    if has_very_dark_nearby:
                        break
                
                if not has_very_dark_nearby:
                    # –ù–µ—Ç –æ—á–µ–Ω—å —Ç–µ–º–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π - —ç—Ç–æ —Ñ–æ–Ω (–∫–ª–µ—Ç–∫–∏), —É–¥–∞–ª—è–µ–º
                    final_pixels.append((255, 255, 255, 0))
                else:
                    # –ï—Å—Ç—å –æ—á–µ–Ω—å —Ç–µ–º–Ω—ã–µ —Å–æ—Å–µ–¥–∏ - —ç—Ç–æ –∫—Ä–∞–π —Ç–µ–∫—Å—Ç–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                    final_pixels.append(pixel)
            else:
                # –¢–µ–º–Ω—ã–π –ø–∏–∫—Å–µ–ª—å - —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                final_pixels.append(pixel)
        else:
            final_pixels.append(pixel)
    
    result.putdata(final_pixels)
    
    # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –º–µ–ª–∫–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ —Ñ–æ–Ω–∞
    mask = Image.new('L', (width, height), 0)
    mask_pixels = [255 if p[3] > 0 else 0 for p in final_pixels]
    mask.putdata(mask_pixels)
    
    # –£–¥–∞–ª—è–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –æ—Å—Ç—Ä–æ–≤–∫–∏ (–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Ñ–æ–Ω–∞) - –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
    mask = mask.filter(ImageFilter.MaxFilter(size=3))  # –†–∞–∑–º–µ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ—á–µ—Ç–Ω—ã–º (1, 3, 5...)
    mask = mask.filter(ImageFilter.MinFilter(size=3))
    
    # –õ–µ–≥–∫–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –∫—Ä–∞–µ–≤ —Ç–µ–∫—Å—Ç–∞
    mask = mask.filter(ImageFilter.GaussianBlur(radius=0.3))
    
    result = Image.composite(result, Image.new('RGBA', (width, height), (255, 255, 255, 0)), mask)
    
    return result

def detect_edges(image):
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫—Ä–∞–µ–≤/–≥—Ä–∞–Ω–∏—Ü –¥–ª—è –∑–∞—â–∏—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤ –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è"""
    width, height = image.size
    if image.mode != 'L':
        gray = image.convert('L')
    else:
        gray = image
    
    # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –∫—Ä–∞–µ–≤ –∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–∑–Ω–∏—Ü—É —è—Ä–∫–æ—Å—Ç–∏
    edge_pixels_list = [0] * (width * height)
    gray_pixels = list(gray.getdata())
    
    for y in range(1, height - 1):
        for x in range(1, width - 1):
            idx = y * width + x
            center = gray_pixels[idx]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ –ø–∏–∫—Å–µ–ª–∏
            neighbors = [
                gray_pixels[(y-1) * width + x],      # –≤–µ—Ä—Ö
                gray_pixels[(y+1) * width + x],      # –Ω–∏–∑
                gray_pixels[y * width + (x-1)],      # –ª–µ–≤–æ
                gray_pixels[y * width + (x+1)],      # –ø—Ä–∞–≤–æ
            ]
            
            # –í—ã—á–∏—Å–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ä–∞–∑–Ω–∏—Ü—É —Å —Å–æ—Å–µ–¥—è–º–∏
            max_diff = max(abs(center - n) for n in neighbors)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∏–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç - —ç—Ç–æ –≥—Ä–∞–Ω–∏—Ü–∞ –æ–±—ä–µ–∫—Ç–∞
            edge_pixels_list[idx] = min(255, max_diff * 2)
    
    return edge_pixels_list

def remove_background_smart(image, ai_guidance=None, user_prompt="", original_image=None, selected_region=None):
    """
    –£–ª—É—á—à–µ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞ - –∑–∞—â–∏—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ –∞–Ω–∞–ª–∏–∑ –≥—Ä–∞–Ω–∏—Ü
    –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ - —É–¥–∞–ª—è–µ—Ç —Ñ–æ–Ω –ª–∏—Å—Ç–∞, –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
    
    Args:
        image: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–º)
        original_image: –∏—Å—Ö–æ–¥–Ω–æ–µ –ø–æ–ª–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ–Ω–∞ –ø—Ä–∏ —Ä—É—á–Ω–æ–º –≤—ã–±–æ—Ä–µ)
        selected_region: –∫–æ—Ä—Ç–µ–∂ (x1, y1, x2, y2) –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    """
    width, height = image.size
    
    if image.mode != 'RGBA':
        image = image.convert('RGBA')
    
    pixels = list(image.getdata())
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ç–µ–∫—Å—Ç–∞
    prompt_lower = user_prompt.lower() if user_prompt else ""
    is_text_extraction = any(word in prompt_lower for word in ['—Ç–µ–∫—Å—Ç', '–Ω–∞–¥–ø–∏—Å—å', 'text', 'inscription', 
                                                                '—Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç', 'only text', '–∏–∑–≤–ª–µ–∫–∏ —Ç–µ–∫—Å—Ç'])
    
    # –î–ª—è —Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
    if is_text_extraction:
        return remove_background_for_text(image)
    
    # –û–ë–ù–ê–†–£–ñ–ê–ï–ú –ì–†–ê–ù–ò–¶–´ –û–ë–™–ï–ö–¢–û–í - —ç—Ç–æ –∑–∞—â–∏—Ç–∏—Ç –∏—Ö –æ—Ç —É–¥–∞–ª–µ–Ω–∏—è
    edge_pixels_list = detect_edges(image)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—Ä–∞—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–≤–µ—Ç–∞ —Ñ–æ–Ω–∞
    # –í–ê–ñ–ù–û: –µ—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤—ã–±—Ä–∞–Ω–Ω–∞—è –æ–±–ª–∞—Å—Ç—å - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–æ–Ω –í–ù–ï –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏!
    edge_colors = []
    edge_zone = 0.15  # 15% –æ—Ç –∫—Ä–∞—è - –∑–æ–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ–Ω–∞
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤—ã–±—Ä–∞–Ω–Ω–∞—è –æ–±–ª–∞—Å—Ç—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ–Ω–∞
    if original_image is not None and selected_region is not None:
        orig_width, orig_height = original_image.size
        if original_image.mode != 'RGBA':
            original_image = original_image.convert('RGBA')
        orig_pixels = list(original_image.getdata())
        x1, y1, x2, y2 = selected_region
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—Ä–∞—è –ò–°–•–û–î–ù–û–ì–û –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–æ –ò–°–ö–õ–Æ–ß–ê–Ø –≤—ã–±—Ä–∞–Ω–Ω—É—é –æ–±–ª–∞—Å—Ç—å
        edge_width = int(orig_width * edge_zone)
        edge_height = int(orig_height * edge_zone)
        
        for y in range(orig_height):
            for x in range(orig_width):
                # –¢–æ–ª—å–∫–æ –∫—Ä–∞—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                if (x < edge_width or x >= orig_width - edge_width or 
                    y < edge_height or y >= orig_height - edge_height):
                    # –ò–°–ö–õ–Æ–ß–ê–ï–ú –≤—ã–±—Ä–∞–Ω–Ω—É—é –æ–±–ª–∞—Å—Ç—å - –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—ä–µ–∫—Ç–æ–º!
                    if not (x1 <= x <= x2 and y1 <= y <= y2):
                        edge_colors.append(orig_pixels[y * orig_width + x])
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ - –∫—Ä–∞—è —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        edge_width = int(width * edge_zone)
        edge_height = int(height * edge_zone)
        
        for y in range(height):
            for x in range(width):
                # –¢–æ–ª—å–∫–æ –∫—Ä–∞—è
                if (x < edge_width or x >= width - edge_width or 
                    y < edge_height or y >= height - edge_height):
                    edge_colors.append(pixels[y * width + x])
    
    edge_width = int(width * edge_zone)
    edge_height = int(height * edge_zone)
    
    for y in range(height):
        for x in range(width):
            # –¢–æ–ª—å–∫–æ –∫—Ä–∞—è
            if (x < edge_width or x >= width - edge_width or 
                y < edge_height or y >= height - edge_height):
                edge_colors.append(pixels[y * width + x])
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ–Ω –ø–æ –∫—Ä–∞—è–º
    edge_colors_rgb = [(r, g, b) for r, g, b, a in edge_colors]
    if edge_colors_rgb:
        most_common_colors = Counter(edge_colors_rgb).most_common(3)
        bg_colors = [color for color, count in most_common_colors]
    else:
        bg_colors = [(255, 255, 255), (240, 240, 240), (200, 200, 200)]
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∑–∞–¥–∞—á–∏
    aggressive_mode = False
    if user_prompt:
        prompt_lower = user_prompt.lower()
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –ø—Ä–æ—Å–∏—Ç —É–¥–∞–ª–∏—Ç—å —Ñ–æ–Ω, –±—ã—Ç—å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º
        if any(word in prompt_lower for word in ['—É–±–µ—Ä–∏ —Ñ–æ–Ω', '—É–¥–∞–ª–∏ —Ñ–æ–Ω', 'remove background', 
                                                  '—É–±–µ—Ä–∏ –∑–∞–¥–Ω–∏–π', '—É–¥–∞–ª–∏ –∑–∞–¥–Ω–∏–π', '—Å–µ—Ä—ã–π —Ñ–æ–Ω', 'gray background']):
            aggressive_mode = True
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å —Ñ–æ–Ω–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–∏—è
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ü–≤–µ—Ç–∞ –ø–æ –≤—Å–µ–π –æ–±–ª–∞—Å—Ç–∏ (–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–≥–æ —Ñ–æ–Ω–∞ –º–∞–π–∫–∏)
    bg_color_variations = []
    for bg_r, bg_g, bg_b in bg_colors:
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–∏–∫—Å–µ–ª–∏ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —ç—Ç–æ—Ç —Ñ–æ–Ω
        similar_count = 0
        for pixel in pixels:
            r, g, b, _ = pixel
            dist = ((r - bg_r) ** 2 + (g - bg_g) ** 2 + (b - bg_b) ** 2) ** 0.5
            if dist < 40:  # –ü–æ—Ö–æ–∂–∏–π —Ü–≤–µ—Ç
                similar_count += 1
        bg_color_variations.append((bg_r, bg_g, bg_b, similar_count))
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–π —Ü–≤–µ—Ç —Ñ–æ–Ω–∞
    bg_color_variations.sort(key=lambda x: x[3], reverse=True)
    primary_bg_color = bg_color_variations[0][:3] if bg_color_variations else bg_colors[0]
    
    new_pixels = []
    
    for i, pixel in enumerate(pixels):
        r, g, b, a = pixel
        y_pos = i // width
        x_pos = i % width
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –∫—Ä–∞—è
        dist_x = min(x_pos, width - x_pos)
        dist_y = min(y_pos, height - y_pos)
        dist_to_edge = min(dist_x, dist_y)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (0 = –Ω–∞ –∫—Ä–∞—é, 1 = –≤ —Ü–µ–Ω—Ç—Ä–µ)
        max_dist = min(width, height) / 2
        normalized_dist = dist_to_edge / max_dist if max_dist > 0 else 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ü–≤–µ—Ç–∞ —Ñ–æ–Ω–∞
        min_distance = float('inf')
        for bg_r, bg_g, bg_b in bg_colors:
            color_distance = ((r - bg_r) ** 2 + (g - bg_g) ** 2 + (b - bg_b) ** 2) ** 0.5
            min_distance = min(min_distance, color_distance)
        
        # –ó–ê–©–ò–¢–ê –û–ë–™–ï–ö–¢–û–í: –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—Ä—Ç—É –≥—Ä–∞–Ω–∏—Ü
        edge_strength = edge_pixels_list[i] if i < len(edge_pixels_list) else 0
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ê–î–ê–ü–¢–ò–í–ù–´–ô –ü–û–†–û–ì —Å –∑–∞—â–∏—Ç–æ–π –æ–±—ä–µ–∫—Ç–æ–≤:
        # - –ù–∞ –∫—Ä–∞—è—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (0-20%): –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –æ–±—ä–µ–∫—Ç–∞
        # - –°—Ä–µ–¥–Ω—è—è –∑–æ–Ω–∞ (20-60%): –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ
        # - –í —Ü–µ–Ω—Ç—Ä–µ (60-100%): –æ—á–µ–Ω—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ - –ø–æ—á—Ç–∏ –Ω–µ —É–¥–∞–ª—è–µ–º
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–≥–æ —Ñ–æ–Ω–∞
        if normalized_dist < 0.2:
            # –ö—Ä–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –æ—á–µ–Ω—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–≥–æ —Ñ–æ–Ω–∞
            threshold = 40 if aggressive_mode else 35  # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞
        elif normalized_dist < 0.5:
            # –°—Ä–µ–¥–Ω—è—è –∑–æ–Ω–∞ - –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–≥–æ —Ñ–æ–Ω–∞
            base_threshold = 35 if aggressive_mode else 40
            threshold = base_threshold + (normalized_dist - 0.2) * 10  # 35/40 –¥–æ 38/43
        else:
            # –¶–µ–Ω—Ç—Ä - —É–º–µ—Ä–µ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ, –Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å
            threshold = 40 if aggressive_mode else 45
        
        # –ï—Å–ª–∏ –ø–∏–∫—Å–µ–ª—å –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ –æ–±—ä–µ–∫—Ç–∞ - –ù–ò–ö–û–ì–î–ê –Ω–µ —É–¥–∞–ª—è–µ–º!
        if edge_strength > 30:  # –°–∏–ª—å–Ω–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ - –∑–∞—â–∏—â–∞–µ–º
            is_background = False
        elif edge_strength > 15:  # –°—Ä–µ–¥–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ - –∑–∞—â–∏—â–∞–µ–º
            is_background = False
        else:
            # –ù–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
            is_background = min_distance < threshold
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –µ—Å–ª–∏ —Ü–≤–µ—Ç –æ—á–µ–Ω—å –±–ª–∏–∑–æ–∫ –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É —Ñ–æ–Ω—É - —É–¥–∞–ª—è–µ–º –¥–∞–∂–µ –≤ —Ü–µ–Ω—Ç—Ä–µ
            if not is_background:
                distance_to_primary = ((r - primary_bg_color[0]) ** 2 + 
                                       (g - primary_bg_color[1]) ** 2 + 
                                       (b - primary_bg_color[2]) ** 2) ** 0.5
                # –ï—Å–ª–∏ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∫ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–º—É —Ñ–æ–Ω—É (—Ñ–æ–Ω –º–∞–π–∫–∏) - —É–¥–∞–ª—è–µ–º
                if distance_to_primary < 30:  # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–≥–æ —Ñ–æ–Ω–∞
                    is_background = True
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –∞–Ω–∞–ª–∏–∑ —Å–æ—Å–µ–¥–Ω–∏—Ö –ø–∏–∫—Å–µ–ª–µ–π
        # –ï—Å–ª–∏ –≤–æ–∫—Ä—É–≥ –º–Ω–æ–≥–æ —Ä–∞–∑–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤ (–Ω–µ —Ñ–æ–Ω–∞) - —ç—Ç–æ —á–∞—Å—Ç—å –æ–±—ä–µ–∫—Ç–∞
        if is_background:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–∂–µ —Ä–µ—à–∏–ª–∏ —É–¥–∞–ª–∏—Ç—å
            neighbor_colors = []
            for dy in [-1, 0, 1]:
                for dx in [-1, 0, 1]:
                    if dx == 0 and dy == 0:
                        continue
                    nx, ny = x_pos + dx, y_pos + dy
                    if 0 <= nx < width and 0 <= ny < height:
                        n_idx = ny * width + nx
                        nr, ng, nb, _ = pixels[n_idx]
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ñ–æ–Ω–∞
                        n_dist = float('inf')
                        for bg_r, bg_g, bg_b in bg_colors:
                            n_color_dist = ((nr - bg_r) ** 2 + (ng - bg_g) ** 2 + (nb - bg_b) ** 2) ** 0.5
                            n_dist = min(n_dist, n_color_dist)
                        neighbor_colors.append(n_dist)
            
            if neighbor_colors:
                # –ï—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π –ù–ï —Ñ–æ–Ω - —ç—Ç–æ —á–∞—Å—Ç—å –æ–±—ä–µ–∫—Ç–∞!
                non_bg_neighbors = sum(1 for d in neighbor_colors if d > 35)
                if non_bg_neighbors >= len(neighbor_colors) * 0.4:  # 40% —Å–æ—Å–µ–¥–µ–π –Ω–µ —Ñ–æ–Ω
                    is_background = False  # –ó–∞—â–∏—â–∞–µ–º - —ç—Ç–æ —á–∞—Å—Ç—å –æ–±—ä–µ–∫—Ç–∞
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —è–≤–Ω—ã–π –æ–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π —Ñ–æ–Ω (–±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)
        if not is_background:
            # –û—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã–π –æ–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π —Ñ–æ–Ω (–±–µ–ª—ã–π/—Å–≤–µ—Ç–ª–æ-—Å–µ—Ä—ã–π) - —É–¥–∞–ª—è–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã
            if edge_strength < 15 and r > 240 and g > 240 and b > 240 and abs(r - g) < 15 and abs(g - b) < 15:
                is_background = True
            # –û—á–µ–Ω—å —Ç–µ–º–Ω—ã–π –æ–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π —Ñ–æ–Ω (—á–µ—Ä–Ω—ã–π/—Ç–µ–º–Ω–æ-—Å–µ—Ä—ã–π) - —É–¥–∞–ª—è–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã
            elif edge_strength < 15 and r < 30 and g < 30 and b < 30:
                is_background = True
            # –°—Ä–µ–¥–Ω–µ-—Å–µ—Ä—ã–π –æ–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π —Ñ–æ–Ω (—Å–µ—Ä—ã–π/–±–∏—Ä—é–∑–æ–≤—ã–π —Ñ–æ–Ω –º–∞–π–∫–∏) - —É–¥–∞–ª—è–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
            elif (edge_strength < 15 and abs(r - g) < 25 and abs(g - b) < 25 and 
                  140 < (r + g + b) / 3 < 210):  # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è —Å–µ—Ä–æ–≥–æ —Ñ–æ–Ω–∞
                is_background = True
        
        if is_background:
            new_pixels.append((255, 255, 255, 0))
        else:
            new_pixels.append((r, g, b, 255))
    
    result = Image.new('RGBA', (width, height))
    result.putdata(new_pixels)
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –∏ —É–ª—É—á—à–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞
    mask = Image.new('L', (width, height), 0)
    mask_pixels = [255 if p[3] > 0 else 0 for p in new_pixels]
    mask.putdata(mask_pixels)
    
    # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –º–µ–ª–∫–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ —Ñ–æ–Ω–∞
    mask = mask.filter(ImageFilter.MaxFilter(size=1))
    mask = mask.filter(ImageFilter.MinFilter(size=1))
    
    # –õ–µ–≥–∫–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ –∫—Ä–∞–µ–≤ –º–∞—Å–∫–∏ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
    mask = mask.filter(ImageFilter.GaussianBlur(radius=0.3))
    
    result = Image.composite(result, Image.new('RGBA', (width, height), (255, 255, 255, 0)), mask)
    
    return result

# HTML —à–∞–±–ª–æ–Ω –±—É–¥–µ—Ç —Ç–∞–∫–æ–π –∂–µ, –Ω–æ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –ø–æ–ª—è –¥–ª—è –≤–≤–æ–¥–∞ –ø—Ä–æ–º–ø—Ç–∞
HTML_TEMPLATE = '''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–Ω—Ç–æ–≤ —Å –ò–ò</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2196F3;
            text-align: center;
        }
        .button {
            background: #2196F3;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 14px;
            margin: 10px 5px;
        }
        .button:hover { background: #1976D2; }
        .button.success { background: #4CAF50; }
        .button.danger { background: #F44336; }
        #imageCanvas, #resultCanvas {
            border: 2px solid #ddd;
            border-radius: 5px;
            cursor: crosshair;
            display: block;
            margin: 20px auto;
            max-width: 100%;
        }
        .info {
            background: #e3f2fd;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
        }
        .controls {
            text-align: center;
            margin: 20px 0;
        }
        input[type="file"], textarea {
            display: none;
        }
        .ai-section {
            background: #fff3e0;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border: 2px solid #ff9800;
        }
        .ai-section textarea {
            display: block;
            width: 100%;
            min-height: 80px;
            padding: 10px;
            margin: 10px 0;
            border: 2px solid #ff9800;
            border-radius: 5px;
            font-size: 14px;
        }
        .method-selector {
            margin: 20px 0;
            text-align: center;
        }
        .method-selector label {
            margin: 0 15px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé® –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–Ω—Ç–æ–≤ –∏ –Ω–∞–¥–ø–∏—Å–µ–π (—Å –ò–ò)</h1>
        
        <div class="method-selector">
            <label><input type="radio" name="method" value="manual" checked> –†—É—á–Ω–æ–π –≤—ã–±–æ—Ä –æ–±–ª–∞—Å—Ç–∏</label>
            <label><input type="radio" name="method" value="ai" id="aiMethodRadio"> –ò–ò –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é</label>
        </div>
        
        <div id="aiSection" class="ai-section" style="display:none;">
            <h3>ü§ñ –ò–ò –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ</h3>
            <p>–û–ø–∏—à–∏—Ç–µ —á—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:</p>
            <textarea id="aiPrompt" placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: '–Ω–∞–¥–ø–∏—Å—å LINKIN PARK', '–∫–∞—Ä—Ç–∏–Ω–∫–∞ —Å –∂–µ–Ω—â–∏–Ω–æ–π', '–ª–æ–≥–æ—Ç–∏–ø –û–ª–∏–º–ø–∏–∞–¥–∞-80' –∏ —Ç.–¥."></textarea>
            <button class="button success" onclick="extractWithAI()">üîç –ò–ò: –ò–∑–≤–ª–µ—á—å –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é</button>
            <div id="aiStatus"></div>
        </div>
        
        <div class="controls">
            <input type="file" id="fileInput" accept="image/*">
            <button class="button" onclick="document.getElementById('fileInput').click()">üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ</button>
        </div>
        
        <div id="imageContainer"></div>
        <div id="resultContainer" style="display:none;">
            <h2>–†–µ–∑—É–ª—å—Ç–∞—Ç:</h2>
            <canvas id="resultCanvas"></canvas>
            <div class="controls">
                <button class="button success" onclick="downloadResult()">üíæ –°–∫–∞—á–∞—Ç—å PNG</button>
            </div>
        </div>
        
        <div class="info" id="info"></div>
    </div>
    
    <script>
        let image = null;
        let canvas = null;
        let ctx = null;
        let startX = 0, startY = 0;
        let isDrawing = false;
        let scale = 1;
        let selection = {x1: 0, y1: 0, x2: 0, y2: 0};
        let originalWidth = 0, originalHeight = 0;
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ò–ò –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        let aiAvailable = false;
        fetch('/check_ai')
        .then(r => r.json())
        .then(data => {
            aiAvailable = data.available || false;
            if (!aiAvailable) {
                // –û—Ç–∫–ª—é—á–∞–µ–º –ò–ò —Ä–µ–∂–∏–º –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                const aiRadio = document.getElementById('aiMethodRadio');
                if (aiRadio) {
                    aiRadio.disabled = true;
                    aiRadio.parentElement.innerHTML += '<span style="color:red;"> (–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ)</span>';
                }
                if (data.has_openai && !data.has_key) {
                    document.getElementById('aiStatus').innerHTML = 
                        '<div style="color:orange; margin-top:10px;">‚ö† OpenAI —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –Ω–æ API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª ~/.openai_api_key</div>';
                } else if (!data.has_openai) {
                    document.getElementById('aiStatus').innerHTML = 
                        '<div style="color:red; margin-top:10px;">‚ùå OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip3 install openai</div>';
                }
            }
        })
        .catch(err => {
            console.log('–ò–ò –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å:', err);
        });
        
        document.querySelectorAll('input[name="method"]').forEach(radio => {
            radio.addEventListener('change', function() {
                if (this.value === 'ai' && !aiAvailable) {
                    alert('–ò–ò —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ OpenAI —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ API –∫–ª—é—á –Ω–∞—Å—Ç—Ä–æ–µ–Ω.');
                    document.querySelector('input[name="method"][value="manual"]').checked = true;
                    document.getElementById('aiSection').style.display = 'none';
                    return;
                }
                document.getElementById('aiSection').style.display = 
                    this.value === 'ai' ? 'block' : 'none';
            });
        });
        
        document.getElementById('fileInput').addEventListener('change', function(e) {
            const file = e.target.files[0];
            if (!file) return;
            
            const formData = new FormData();
            formData.append('file', file);
            
            fetch('/upload', {
                method: 'POST',
                body: formData
            })
            .then(r => r.json())
            .then(data => {
                if (data.success) {
                    loadImage();
                } else {
                    alert('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: ' + data.error);
                }
            });
        });
        
        function loadImage() {
            fetch('/image')
            .then(r => r.json())
            .then(data => {
                if (!data.success) {
                    alert('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è');
                    return;
                }
                
                image = new Image();
                image.src = 'data:image/png;base64,' + data.data;
                originalWidth = data.width;
                originalHeight = data.height;
                
                image.onload = function() {
                    canvas = document.createElement('canvas');
                    canvas.id = 'imageCanvas';
                    ctx = canvas.getContext('2d');
                    
                    const maxWidth = 1000;
                    const maxHeight = 800;
                    scale = Math.min(maxWidth / data.width, maxHeight / data.height, 1);
                    
                    canvas.width = data.width * scale;
                    canvas.height = data.height * scale;
                    ctx.drawImage(image, 0, 0, canvas.width, canvas.height);
                    
                    document.getElementById('imageContainer').innerHTML = '';
                    document.getElementById('imageContainer').appendChild(canvas);
                    document.getElementById('info').innerHTML = 
                        '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ. –í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è.';
                    
                    const extractBtn = document.createElement('button');
                    extractBtn.className = 'button success';
                    extractBtn.textContent = 'üîç –ò–∑–≤–ª–µ—á—å –ø—Ä–∏–Ω—Ç (—Ä—É—á–Ω–æ–π)';
                    extractBtn.onclick = extractRegion;
                    extractBtn.style.display = 'block';
                    extractBtn.style.margin = '20px auto';
                    document.getElementById('imageContainer').appendChild(extractBtn);
                    
                    setupCanvasEvents();
                };
            });
        }
        
        function setupCanvasEvents() {
            canvas.addEventListener('mousedown', function(e) {
                const rect = canvas.getBoundingClientRect();
                startX = (e.clientX - rect.left) / scale;
                startY = (e.clientY - rect.top) / scale;
                isDrawing = true;
            });
            
            canvas.addEventListener('mousemove', function(e) {
                if (!isDrawing) return;
                const rect = canvas.getBoundingClientRect();
                const currentX = (e.clientX - rect.left) / scale;
                const currentY = (e.clientY - rect.top) / scale;
                
                selection.x1 = Math.round(Math.min(startX, currentX));
                selection.y1 = Math.round(Math.min(startY, currentY));
                selection.x2 = Math.round(Math.max(startX, currentX));
                selection.y2 = Math.round(Math.max(startY, currentY));
                
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(image, 0, 0, canvas.width, canvas.height);
                
                ctx.strokeStyle = 'red';
                ctx.lineWidth = 3;
                ctx.strokeRect(
                    selection.x1 * scale,
                    selection.y1 * scale,
                    (selection.x2 - selection.x1) * scale,
                    (selection.y2 - selection.y1) * scale
                );
            });
            
            canvas.addEventListener('mouseup', function(e) {
                isDrawing = false;
            });
        }
        
        function extractRegion() {
            if (!image || !canvas) {
                alert('–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤—ã–¥–µ–ª–∏—Ç–µ –æ–±–ª–∞—Å—Ç—å!');
                return;
            }
            
            if (selection.x2 <= selection.x1 || selection.y2 <= selection.y1) {
                alert('–°–Ω–∞—á–∞–ª–∞ –≤—ã–¥–µ–ª–∏—Ç–µ –æ–±–ª–∞—Å—Ç—å –º—ã—à—å—é!');
                return;
            }
            
            extractAndProcess(selection);
        }
        
        function extractWithAI() {
            const prompt = document.getElementById('aiPrompt').value.trim();
            if (!prompt) {
                alert('–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å!');
                return;
            }
            
            document.getElementById('aiStatus').innerHTML = '‚è≥ –ò–ò –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...';
            
            fetch('/extract_ai', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({prompt: prompt})
            })
            .then(r => r.json())
            .then(data => {
                if (data.success && data.coords) {
                    document.getElementById('aiStatus').innerHTML = 
                        '‚úì –û–±–ª–∞—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ò–ò. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...';
                    
                    // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ–º
                    setTimeout(() => {
                        extractAndProcess(data.coords);
                    }, 500);
                } else {
                    document.getElementById('aiStatus').innerHTML = 
                        '‚ùå –û—à–∏–±–∫–∞: ' + (data.error || '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–±–ª–∞—Å—Ç—å');
                }
            })
            .catch(err => {
                document.getElementById('aiStatus').innerHTML = 
                    '‚ùå –û—à–∏–±–∫–∞: ' + err.message;
            });
        }
        
        function extractAndProcess(coords) {
            fetch('/extract', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify(coords)
            })
            .then(r => r.json())
            .then(data => {
                if (data.success) {
                    const resultCanvas = document.getElementById('resultCanvas');
                    const resultCtx = resultCanvas.getContext('2d');
                    const resultImg = new Image();
                    resultImg.src = 'data:image/png;base64,' + data.data;
                    resultImg.onload = function() {
                        resultCanvas.width = resultImg.width;
                        resultCanvas.height = resultImg.height;
                        resultCtx.drawImage(resultImg, 0, 0);
                        document.getElementById('resultContainer').style.display = 'block';
                        document.getElementById('info').innerHTML = 
                            '‚úì –ü—Ä–∏–Ω—Ç –∏–∑–≤–ª–µ—á–µ–Ω! –†–∞–∑–º–µ—Ä: ' + data.width + ' x ' + data.height + ' –ø–∏–∫—Å–µ–ª–µ–π';
                    };
                } else {
                    alert('–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: ' + data.error);
                }
            })
            .catch(err => {
                alert('–û—à–∏–±–∫–∞: ' + err.message);
            });
        }
        
        function downloadResult() {
            window.location.href = '/result';
        }
    </script>
</body>
</html>'''

class WebHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        path = urllib.parse.urlparse(self.path).path
        
        if path == '/':
            self.send_response(200)
            self.send_header('Content-type', 'text/html; charset=utf-8')
            self.end_headers()
            self.wfile.write(HTML_TEMPLATE.encode('utf-8'))
        elif path == '/image':
            self.send_image()
        elif path == '/result':
            self.get_result()
        elif path == '/check_ai':
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ò–ò
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥—É–ª—è
            has_key = load_openai_key() if HAS_OPENAI else False
            
            self.wfile.write(json.dumps({
                'has_openai': HAS_OPENAI,
                'has_key': has_key,
                'available': HAS_OPENAI and has_key
            }).encode())
        else:
            self.send_error(404)
    
    def do_POST(self):
        if self.path == '/upload':
            self.handle_upload()
        elif self.path == '/extract':
            self.extract_region()
        elif self.path == '/extract_ai':
            self.extract_with_ai()
        else:
            self.send_error(404)
    
    def send_image(self):
        global global_image
        if global_image is None:
            self.send_error(404)
            return
        
        try:
            buffer = io.BytesIO()
            global_image.save(buffer, format='PNG')
            img_data = base64.b64encode(buffer.getvalue()).decode()
            
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(json.dumps({
                'success': True,
                'data': img_data,
                'width': global_image.size[0],
                'height': global_image.size[1]
            }).encode())
        except Exception as e:
            self.send_error(500, str(e))
    
    def handle_upload(self):
        global global_image
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length == 0:
                raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
            
            post_data = self.rfile.read(content_length)
            
            content_type = self.headers.get('Content-Type', '')
            if 'boundary=' in content_type:
                boundary = content_type.split('boundary=')[1].encode()
                parts = post_data.split(b'--' + boundary)
                
                for part in parts:
                    if b'Content-Type:' in part:
                        header_end = part.find(b'\r\n\r\n')
                        if header_end > 0:
                            file_data = part[header_end+4:].rstrip(b'\r\n')
                            global_image = Image.open(io.BytesIO(file_data))
                            break
            
            if global_image is None:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ñ–∞–π–ª")
            
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(json.dumps({'success': True}).encode())
        except Exception as e:
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(json.dumps({'success': False, 'error': str(e)}).encode())
    
    def extract_with_ai(self):
        global global_image, global_prompt
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode())
            
            prompt = data.get('prompt', '')
            if not prompt:
                raise ValueError("–ü—Ä–æ–º–ø—Ç –Ω–µ —É–∫–∞–∑–∞–Ω")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–æ–Ω–∞
            global_prompt = prompt
            
            if global_image is None:
                raise ValueError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                global_image.save(tmp.name, 'PNG')
                tmp_path = tmp.name
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ò–ò –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–±–ª–∞—Å—Ç–∏
            coords, error = extract_with_ai(tmp_path, prompt)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                os.unlink(tmp_path)
            except:
                pass
            
            if error:
                raise ValueError(error)
            
            if coords:
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                self.wfile.write(json.dumps({
                    'success': True,
                    'coords': coords
                }).encode())
            else:
                raise ValueError("–ò–ò –Ω–µ —Å–º–æ–≥ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–±–ª–∞—Å—Ç—å")
                
        except Exception as e:
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(json.dumps({
                'success': False,
                'error': str(e)
            }).encode())
    
    def extract_region(self):
        global global_image, global_result, global_prompt
        
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode())
            
            x1 = int(data.get('x1', 0))
            y1 = int(data.get('y1', 0))
            x2 = int(data.get('x2', 0))
            y2 = int(data.get('y2', 0))
            
            if global_image is None:
                raise ValueError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            
            cropped = global_image.crop((x1, y1, x2, y2))
            cropped = cropped.convert('RGBA')
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞
            # –í–ê–ñ–ù–û: –ø–µ—Ä–µ–¥–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏,
            # —á—Ç–æ–±—ã –∞–ª–≥–æ—Ä–∏—Ç–º –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª —Ñ–æ–Ω –í–ù–ï –≤—ã–±—Ä–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏, –∞ –Ω–µ –∫—Ä–∞—è –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            result = remove_background_smart(
                cropped, 
                user_prompt=global_prompt,
                original_image=global_image,
                selected_region=(x1, y1, x2, y2)
            )
            global_result = result
            # –û—á–∏—â–∞–µ–º –ø—Ä–æ–º–ø—Ç –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞)
            global_prompt = ""
            
            buffer = io.BytesIO()
            result.save(buffer, format='PNG')
            img_data = base64.b64encode(buffer.getvalue()).decode()
            
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(json.dumps({
                'success': True,
                'data': img_data,
                'width': result.size[0],
                'height': result.size[1]
            }).encode())
        except Exception as e:
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(json.dumps({'success': False, 'error': str(e)}).encode())
    
    def get_result(self):
        global global_result
        if global_result is None:
            self.send_error(404)
            return
        
        try:
            buffer = io.BytesIO()
            global_result.save(buffer, format='PNG')
            img_data = buffer.getvalue()
            
            self.send_response(200)
            self.send_header('Content-type', 'image/png')
            self.send_header('Content-Disposition', 'attachment; filename="extracted.png"')
            self.send_header('Content-Length', str(len(img_data)))
            self.end_headers()
            self.wfile.write(img_data)
        except Exception as e:
            self.send_error(500, str(e))
    
    def log_message(self, format, *args):
        pass

def start_server(port=8000):
    server = HTTPServer(('localhost', port), WebHandler)
    print(f"\n{'='*60}")
    print("  üåê –í–ï–ë-–ò–ù–¢–ï–†–§–ï–ô–° –° –ò–ò –ü–û–î–î–ï–†–ñ–ö–û–ô")
    print("="*60)
    print(f"\n‚úì –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞: http://localhost:{port}")
    print("  –ë—Ä–∞—É–∑–µ—Ä –¥–æ–ª–∂–µ–Ω –æ—Ç–∫—Ä—ã—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏...")
    
    if HAS_OPENAI:
        if load_openai_key():
            print("  ‚úì OpenAI API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω - –ò–ò —Ñ—É–Ω–∫—Ü–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã")
        else:
            print("  ‚ö† OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")
            print("    –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª ~/.openai_api_key —Å –≤–∞—à–∏–º API –∫–ª—é—á–æ–º")
            print("    –ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è: export OPENAI_API_KEY='your-key'")
    else:
        print("  ‚ö† OpenAI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - –ò–ò —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
        print("    –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip3 install openai")
    
    print("\n  –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\n")
    
    threading.Timer(1.0, lambda: webbrowser.open(f'http://localhost:{port}')).start()
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\n\n–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞...")
        server.shutdown()

def main():
    try:
        start_server()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
